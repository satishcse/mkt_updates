{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satishcse/mkt_updates/blob/main/Various_Chartink_links_download_all_combined.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d24fb241",
      "metadata": {
        "id": "d24fb241"
      },
      "source": [
        "# Chartink results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/root/airflow/dags'\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "  os.makedirs(folder_path)"
      ],
      "metadata": {
        "id": "cHfKwfhY3ngu"
      },
      "id": "cHfKwfhY3ngu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "from googleapiclient.discovery import build\n",
        "from google.colab import drive\n",
        "\n",
        "def run_colab_notebook(notebook_id):\n",
        "    # Authenticate and build the Google Colab API client\n",
        "    creds, _ = google.auth.default()\n",
        "    service = build('colab', 'v1', credentials=creds)\n",
        "\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # Open the specified notebook\n",
        "    notebook = service.notebooks().get(notebookId=notebook_id).execute()\n",
        "    cells = notebook.get('cells', [])\n",
        "\n",
        "    # Execute each cell in the notebook\n",
        "    for cell in cells:\n",
        "        result = service.notebooks().execute(notebookId=notebook_id, body=cell).execute()\n"
      ],
      "metadata": {
        "id": "-Y6Beu3J4800"
      },
      "id": "-Y6Beu3J4800",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from airflow.operators.python import PythonOperator\n",
        "from airflow.models import DAG\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "4iOk38fe5RPU"
      },
      "id": "4iOk38fe5RPU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open ('/root/airflow/dags/run_colab_notebook.py', 'w+') as f:\n",
        "  f.write(\"default_args = {    'owner': 'airflow','depends_on_past': False,    'start_date': datetime(2023, 2, 2),    'email_on_failure': False,    'email_on_retry': False,    'retries': 1,    'retry_delay': timedelta(minutes=3)} dag = DAG(    'run_colab_notebook',    default_args=default_args,    schedule=timedelta(minutes=1)) run_colab_notebook = PythonOperator(    task_id='run_colab_notebook',    python_callable=run_colab_notebook,    dag=dag)\")\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "4r4QDepL5V7x"
      },
      "id": "4r4QDepL5V7x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !airflow worker"
      ],
      "metadata": {
        "id": "fO7ccxWA78cB"
      },
      "id": "fO7ccxWA78cB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !airflow webserver -p 8000\n",
        "\n",
        "import subprocess\n",
        "subprocess.call(\"airflow webserver -p 8000 -k\", shell=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcyFOQpm9FhY",
        "outputId": "319d3a1a-6483-4f89-9a26-0935829020d0"
      },
      "id": "xcyFOQpm9FhY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ping 172.28.0.12\n",
        "# installing ping utility\n",
        "# !apt-get update && apt-get install iputils-ping -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2pRJL6NDtIU",
        "outputId": "68f8f74e-fe2c-481f-a01b-eed8afc3f115"
      },
      "id": "k2pRJL6NDtIU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PING 172.28.0.12 (172.28.0.12) 56(84) bytes of data.\n",
            "64 bytes from 172.28.0.12: icmp_seq=1 ttl=64 time=0.068 ms\n",
            "64 bytes from 172.28.0.12: icmp_seq=2 ttl=64 time=0.060 ms\n",
            "64 bytes from 172.28.0.12: icmp_seq=3 ttl=64 time=0.062 ms\n",
            "\n",
            "--- 172.28.0.12 ping statistics ---\n",
            "3 packets transmitted, 3 received, 0% packet loss, time 2055ms\n",
            "rtt min/avg/max/mdev = 0.060/0.063/0.068/0.003 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://172.28.0.12:8000/api/experimental/dags/run_colab_notebook/dag_runs\"\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "data = {\n",
        "    'run_id': 'manual__' + str(datetime.now().isoformat()),\n",
        "    'execution_date': str(datetime.now().isoformat())\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "print(response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "PdgYEQdNJYnZ",
        "outputId": "8ab49f89-c676-4d48-b8f8-ae650fb0d12d"
      },
      "id": "PdgYEQdNJYnZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    159\u001b[0m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    168\u001b[0m                 self, \"Failed to establish a new connection: %s\" % e)\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f78d38bb2b0>: Failed to establish a new connection: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0m\u001b[1;32m    638\u001b[0m                                         _stacktrace=sys.exc_info()[2])\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='172.28.0.12', port=8000): Max retries exceeded with url: /api/experimental/dags/run_colab_notebook/dag_runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f78d38bb2b0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-a658d32d0e2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='172.28.0.12', port=8000): Max retries exceeded with url: /api/experimental/dags/run_colab_notebook/dag_runs (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f78d38bb2b0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n",
        "\n",
        "host_name = socket.gethostname()\n",
        "host_ip = socket.gethostbyname(host_name)\n",
        "\n",
        "print(\"Hostname:\", host_name)\n",
        "print(\"IP address:\", host_ip)\n",
        "\n",
        "# Hostname: 29fbdf8dee31\n",
        "# IP address: 172.28.0.12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Qh7MrT-TpM",
        "outputId": "6c06e38e-6ef3-4174-fd0c-7e773c1cad5f"
      },
      "id": "Y-Qh7MrT-TpM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hostname: 29fbdf8dee31\n",
            "IP address: 172.28.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/satishcse/mkt_updates.git\n",
        "%cd mkt_updates"
      ],
      "metadata": {
        "id": "dwTznB9kcjla"
      },
      "id": "dwTznB9kcjla",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd8c302",
      "metadata": {
        "code_folding": [],
        "id": "1fd8c302"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "# import sys\n",
        "# import os\n",
        "import datetime as dt\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "Charting_Link = \"https://chartink.com/screener/\"\n",
        "Charting_url = 'https://chartink.com/screener/process'\n",
        "\n",
        "#You need to copy paste condition in below mentioned Condition variable\n",
        "\n",
        "#Condition = \"( {136699} ( latest high - latest low < 1 day ago high - 1 day ago low and latest high - latest low < 2 days ago high - 2 days ago low and latest high - latest low < 3 days ago high - 3 days ago low and latest high - latest low < 4 days ago high - 4 days ago low and latest high - latest low < 5 days ago high - 5 days ago low and latest high - latest low < 6 days ago high - 6 days ago low ) )\"\n",
        "\n",
        "\n",
        "#ID_File1:\n",
        "Condition_Sector_performance = \"( {45603} ( latest close > 1 ) )\"\n",
        "\n",
        "#ID_File2:\n",
        "Condition_1hr_OBV_DIV = \"( {33492} ( ( {33492} ( latest min( 5 , latest rsi( 14 ) ) > 5 days ago max( 5 , latest rsi( 14 ) ) and latest min( 5 , latest obv ) > 5 days ago max( 5 , latest obv ) and latest min( 5 , latest low ) < 5 days ago max( 5 , latest low ) and latest close > 1 day ago max( 3 , latest high ) ) ) ) ) \"\n",
        "Condition_1hr_OBV_DIV_BN = \"( {136699} ( ( {136699} ( latest min( 5 , latest rsi( 14 ) ) > 5 days ago max( 5 , latest rsi( 14 ) ) and latest min( 5 , latest obv ) > 5 days ago max( 5 , latest obv ) and latest min( 5 , latest low ) < 5 days ago max( 5 , latest low ) and latest close > 1 day ago max( 3 , latest high ) ) ) ) ) \"\n",
        "Condition_ID_Buy_PSAR = \"( {33489} ( latest parabolic sar( 0.04,0.02,0.2 ) < latest ema( close,9 ) and 1 day ago  parabolic sar( 0.04,0.02,0.2 ) >= 1 day ago  ema( close,9 ) ) )\" \n",
        "Condition_ID_Volume_Shocker = \"( {33489} ( ( {33489} ( [0] 5 minute wma( close,2 ) >= [0] 5 minute wma( close,3 ) and [0] 5 minute close > [-1] 5 minute high and [0] 5 minute volume >= [0] 5 minute sma( volume,10 ) * 1.250 ) ) or( {33489} ( [0] 5 minute wma( close,2 ) <= [0] 5 minute wma( close,3 ) and [0] 5 minute close < [-1] 5 minute low and [0] 5 minute volume >= [0] 5 minute sma( volume,10 ) * 1.25 ) ) ) )\"\n",
        "Condition_High_relative_volume_spurt = \"( {33489} ( [0] 5 minute volume > ( ( [-1] 5 minute volume + [-2] 5 minute volume + [-3] 5 minute volume ) / 3 ) * 5 and latest close > 80 and latest volume > 100000 ) )\"\n",
        "Condition_OH = \"( {cash} ( latest open = latest high and( {cash} ( ( {33489} ( latest open = latest high ) ) ) ) ) ) \"\n",
        "Condition_OL = \"( {cash} ( latest open = latest low and( {cash} ( ( {33489} ( latest open = latest low ) ) ) ) ) ) \"\n",
        "\n",
        "#EOD_File1:\n",
        "Condition_Volume_Shocker = \"( {57960} ( latest volume > latest sma( volume,10 ) * 2 and( {cash} ( latest close > 1 day ago close * 1.05 or latest close < 1 day ago close * 0.95 ) ) ) )\"\n",
        "Condition_BN_NR7 = \"( {136699} ( latest high - latest low < 1 day ago high - 1 day ago low and latest high - latest low < 2 days ago high - 2 days ago low and latest high - latest low < 3 days ago high - 3 days ago low and latest high - latest low < 4 days ago high - 4 days ago low and latest high - latest low < 5 days ago high - 5 days ago low and latest high - latest low < 6 days ago high - 6 days ago low ) ) \" \n",
        "Condition_BN_NCPR = \"( {136699} ( abs( ( ( ( latest high + latest low + latest close / 3 ) + ( ( latest high + latest low + latest close / 3 ) - ( latest high + latest low / 2 ) ) - ( latest high + latest low / 2 ) ) ) ) < ( latest close * 0.001 ) and latest close > 300 ) )\"\n",
        "Condition_NCPR_KGS = \"( {33489} ( abs( ( ( ( latest high + latest low + latest close / 3 ) + ( ( latest high + latest low + latest close / 3 ) - ( latest high + latest low / 2 ) ) - ( latest high + latest low / 2 ) ) ) ) < ( latest close * 0.001 ) and latest close > 300 ) )\"\n",
        "Condition_OBV_RSI_Buy = \"( {33489} ( latest rsi( 2 ) > 60 and( latest close - latest open ) / ( latest high - latest low ) > 0.55 and latest sma( volume,10 ) > 300000 and latest close < 1500 and latest adx di positive( 14 ) >= latest adx di negative( 14 ) and latest adx( 14 ) > 21 and latest close >= 15 ) )\"\n",
        "Condition_Strong_Stocks = \"( {57960} ( abs( latest close - 124 days ago close ) * 100 / 124 days ago close > 40 and market cap > 500 and latest close > 1 day ago close ) )\"\n",
        "Condition_Bullish_Harami_N100 = \"( {33619} ( 2 days ago high >= 2 days ago open and 2 days ago close <= 2 days ago open and 2 days ago low <= 2 days ago close and 1 day ago high <= 2 days ago high and 1 day ago close <= 2 days ago open and 1 day ago open >= 2 days ago close and 1 day ago low >= 2 days ago low and 1 day ago close > 1 day ago open and latest close >= 2 days ago high and( {cash} ( latest open >= 1 day ago close ) ) and latest close >= 30 ) )\"\n",
        "\n",
        "\n",
        "#Fundamental_scans\n",
        "\n",
        "#FS_File1:\n",
        "Condition_FII_SH_increase = \"( {33489} ( quarterly foreign institutional investors percentage > 1 quarter ago foreign institutional investors percentage and quarterly foreign institutional investors percentage > 2 quarter ago foreign institutional investors percentage and weekly close > 1 week ago close and quarterly net profit/reported profit after tax > 10 and yearly return on capital employed percentage > 15 ) ) \"\n",
        "#Eps Increase , Stock near 15% of 52 week high , Close above 50 ema , Market cap>2000 cr, ROE and ROCE >20\n",
        "Condition_Fundamental_Tenchnical_Swing = \"( {cash} ( quarterly eps after extraordinary items diluted >= 1 quarter ago eps after extraordinary items diluted and 1 quarter ago eps after extraordinary items diluted >= 2 quarter ago eps after extraordinary items diluted and 2 quarter ago eps after extraordinary items diluted >= 3 quarter ago eps after extraordinary items diluted and market cap > 2000 and latest close >= latest max( 252 , latest high ) * .80 and latest close > latest ema( latest close , 50 ) and latest volume > 100000 and yearly return on capital employed percentage > 20 and yearly return on net worth percentage >= 20 ) ) \"\n",
        "Condition_Zero_Debt_Momentum = \"( {cash} ( latest volume > 500000 and latest close > latest ema( close,200 ) and latest ema( close,50 ) > latest ema( close,200 ) and latest ema( close,50 ) > latest ema( close,100 ) and latest ema( close,40 ) > latest ema( close,80 ) and latest ema( close,20 ) > latest ema( close,50 ) and latest ema( close,150 ) > latest ema( close,250 ) and total loans = 0 and latest close > latest ema( close,150 ) and net profit[yearly] > 10 and sales turnover[yearly] > 10 ) ) \"\n",
        "Condition_FIPA_above_all_SMAs = \"( {57960} ( latest close > latest ema( latest close , 200 ) and latest close > latest ema( latest close , 100 ) and latest close > latest ema( latest close , 50 ) and latest close > latest ema( latest close , 20 ) and latest volume > 500000 and earning per share[eps] > prev year eps and yearly net profit/reported profit after tax > 1 year ago net profit/reported profit after tax and yearly net sales > 1 year ago net sales and market cap > 10000 ) )\"\n",
        "Condition_Outperforming_BM_1W_3M = \"( {cash} ( ( {cash} ( ( latest close - 55 days ago close ) * 100 / 55 days ago close > 12 and( latest close - 21 days ago close ) * 100 / 21 days ago close > 12 and( latest close - 123 days ago close ) * 100 / 123 days ago close > 16 and( latest close - 5 days ago close ) * 100 / 5 days ago close > 8 and latest close >= latest supertrend( 7 , 3 ) and weekly rsi( 14 ) >= 59 and monthly rsi( 14 ) >= 50 and latest rsi( 14 ) >= 50 and latest close > latest upper bollinger band( 20 , 2 ) and weekly close > latest upper bollinger band( 20 , 2 ) and monthly close > latest upper bollinger band( 20 , 2 ) and latest close > latest open and latest close > 1 day ago high ) ) and latest volume > 300000 and market cap >= 300 ) )\"\n",
        "\n",
        "\n",
        "#Candlestick patters scans\n",
        "\n",
        "#CS_ID_File1:\n",
        "Condition_Tweezer_top_15m_N50 = \"( {33492} ( ( {cash} ( [0] 15 minute high != greatest(  [0] 15 minute open, [0] 15 minute close  ) and [-1] 15 minute high != greatest(  [-1] 15 minute open, [-1] 15 minute close  ) and [0] 15 minute high = [-1] 15 minute high ) ) or( {cash} ( [0] 15 minute high = greatest(  [0] 15 minute open, [0] 15 minute close  ) and [-1] 15 minute high = greatest(  [-1] 15 minute open, [-1] 15 minute close  ) and [0] 15 minute high = [-1] 15 minute high ) ) ) )\"\n",
        "Condition_Bullish_Hammer_15m_N500 = \"( {57960} ( abs( [0] 15 minute open - [0] 15 minute close ) > ( [0] 15 minute high - [0] 15 minute low ) * 0.05 and abs( [0] 15 minute open - [0] 15 minute close ) < ( [0] 15 minute high - [0] 15 minute low ) * 0.50 and 0.50 * ( [0] 15 minute open + [0] 15 minute close ) - [0] 15 minute low > ( [0] 15 minute high - [0] 15 minute low ) * 0.80 and [0] 15 minute low = latest low and [0] 15 minute {custom_indicator_14779_start}\\\"greatest(   close,  open  ) - least(   open,  close  )\\\"{custom_indicator_14779_end} >= 0.80 ) )\"\n",
        "\n",
        "#CS_EOD_File1:\n",
        "Condition_Hanging_Man_N100 = \"( {33619} ( latest open > latest close and abs( latest open - latest close ) > ( latest high - latest low ) * 0.3 and abs( latest open - latest close ) < ( latest high - latest low ) * 0.50 and 0.50 * ( latest open + latest close ) - latest low > ( latest high - latest low * 0.70 ) and latest high = weekly high ) ) \"\n",
        "Condition_Bullish_Hammer_Daily_N50 = \"( {33492} ( ( {33492} ( ( latest close - latest low ) > ( latest high - latest open ) * 3 and latest close >= latest open ) ) or( {33492} ( ( latest open - latest low ) > ( latest high - latest close ) * 3 and latest open >= latest close ) ) ) )\"\n",
        "Condition_Bullish_Hammer_weekly_N500_near_BB = \"( {57960} ( latest close > 50 and latest volume > 50000 and latest rsi( 14 ) > 55 and latest adx di positive( 14 ) > latest adx di negative( 14 ) and weekly close > weekly sma( weekly close , 200 ) and( {57960} ( ( {57960} ( weekly high < weekly lower bollinger band( 20 , 2 ) * 1.03 and weekly high > weekly lower bollinger band( 20 , 2 ) * 0.975 ) ) or( {57960} ( weekly close < weekly sma( weekly close , 20 ) * 1.05 and weekly close > weekly sma( weekly close , 20 ) ) ) ) ) and( {57960} ( ( {57960} ( 1 week ago close > 1 week ago open and weekly high < 1 week ago close ) ) or( {57960} ( 1 week ago open > 1 week ago close and weekly high < 1 week ago open ) ) ) ) and( {57960} ( ( {57960} ( ( weekly high - weekly low ) > 3 * ( weekly open - weekly close ) and( weekly close - weekly low ) / ( 0.001 + weekly high - weekly low ) > 0.6 and( weekly open - weekly low ) / ( 0.001 + weekly high - weekly low ) > 0.6 ) ) or( {57960} ( weekly open < weekly close and weekly high < weekly lower bollinger band( 20 , 2 ) * 1.05 and( weekly open - weekly low ) / ( weekly high - weekly open ) >= 2 ) ) ) ) ) )\"\n",
        "\n",
        "Condition_Weekly_NCPR_KGS = \"( {33489} ( abs( ( ( ( weekly high + weekly low + weekly close / 3 ) + ( ( weekly high + weekly low + weekly close / 3 ) - ( weekly high + weekly low / 2 ) ) - ( weekly high + weekly low / 2 ) ) ) ) < ( weekly close * 0.005 ) and weekly close > 100 ) )\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00b6dab",
      "metadata": {
        "id": "f00b6dab"
      },
      "outputs": [],
      "source": [
        "def GetDataFromChartink(payload):\n",
        "    payload = {'scan_clause': payload}\n",
        "\n",
        "    with requests.Session() as s:\n",
        "        r = s.get(Charting_Link)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        csrf = soup.select_one(\"[name='csrf-token']\")['content']\n",
        "        s.headers['x-csrf-token'] = csrf\n",
        "        r = s.post(Charting_url, data=payload)\n",
        "\n",
        "        df = pd.DataFrame()\n",
        "        for item in r.json()['data']:\n",
        "            df = df.append(item, ignore_index=True)\n",
        "#             df = pd.concat(item)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a85f462f",
      "metadata": {
        "id": "a85f462f"
      },
      "outputs": [],
      "source": [
        "# ID_File1:\n",
        "data_Sector_performance = GetDataFromChartink(Condition_Sector_performance)\n",
        "if not data_Sector_performance.empty:\n",
        "    data_Sector_performance.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_Sector_performance = data_Sector_performance.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "# ID_File2:\n",
        "data_1hr_OBV_DI = GetDataFromChartink(Condition_1hr_OBV_DIV)\n",
        "if not data_1hr_OBV_DI.empty:\n",
        "    data_1hr_OBV_DI.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_1hr_OBV_DI = data_1hr_OBV_DI.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "data_1hr_OBV_DI_BN = GetDataFromChartink(Condition_1hr_OBV_DIV_BN)\n",
        "if not data_1hr_OBV_DI_BN.empty:\n",
        "    data_1hr_OBV_DI_BN.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_1hr_OBV_DI_BN = data_1hr_OBV_DI_BN.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "data_ID_Buy_PSAR = GetDataFromChartink(Condition_ID_Buy_PSAR)\n",
        "if not data_ID_Buy_PSAR.empty:\n",
        "    data_ID_Buy_PSAR.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_ID_Buy_PSAR = data_ID_Buy_PSAR.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "data_ID_Volume_Shocker = GetDataFromChartink(Condition_ID_Volume_Shocker)\n",
        "if not data_ID_Volume_Shocker.empty:\n",
        "    data_ID_Volume_Shocker.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_ID_Volume_Shocker = data_ID_Volume_Shocker.sort_values(by='volume', ascending=False)\n",
        "    \n",
        "data_High_relative_volume_spurt = GetDataFromChartink(Condition_High_relative_volume_spurt)\n",
        "if not data_High_relative_volume_spurt.empty:\n",
        "    data_High_relative_volume_spurt.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_High_relative_volume_spurt = data_High_relative_volume_spurt.sort_values(by='volume', ascending=False)\n",
        "\n",
        "data_OH = GetDataFromChartink(Condition_OH)\n",
        "if not data_OH.empty:\n",
        "    data_OH.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_OH = data_OH.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "data_OL = GetDataFromChartink(Condition_OL)\n",
        "if not data_OL.empty:\n",
        "    data_OL.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_OL = data_OL.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "# CS_File1:\n",
        "data_Tweezer_top_15m_N50 = GetDataFromChartink(Condition_Tweezer_top_15m_N50)\n",
        "if not data_Tweezer_top_15m_N50.empty:\n",
        "    data_Tweezer_top_15m_N50.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_Tweezer_top_15m_N50 = data_Tweezer_top_15m_N50.sort_values(by='volume', ascending=False)\n",
        "\n",
        "data_Bullish_Hammer_15m_N500 = GetDataFromChartink(Condition_Bullish_Hammer_15m_N500)\n",
        "if not data_Bullish_Hammer_15m_N500.empty:\n",
        "    data_Bullish_Hammer_15m_N500.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "    data_Bullish_Hammer_15m_N500 = data_Bullish_Hammer_15m_N500.sort_values(by='volume', ascending=False)\n",
        "    \n",
        "    \n",
        "if dt.datetime.now().time().strftime(\"%H:%M:%S\") >= '15:25:00':\n",
        "    # EOD_File1:    \n",
        "    data_Volume_Shocker = GetDataFromChartink(Condition_Volume_Shocker)\n",
        "    if not data_Volume_Shocker.empty:\n",
        "        data_Volume_Shocker.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Volume_Shocker = data_Volume_Shocker.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "    data_BN_NR7 = GetDataFromChartink(Condition_BN_NR7)\n",
        "    if not data_BN_NR7.empty:\n",
        "        data_BN_NR7.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_BN_NR7 = data_BN_NR7.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "    data_BN_NCPR = GetDataFromChartink(Condition_BN_NCPR)\n",
        "    if not data_BN_NCPR.empty:\n",
        "        data_BN_NCPR.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_BN_NCPR = data_BN_NCPR.sort_values(by='per_chg', ascending=False)\n",
        "\n",
        "    data_NCPR_KGS = GetDataFromChartink(Condition_NCPR_KGS)\n",
        "    if not data_NCPR_KGS.empty:\n",
        "        data_NCPR_KGS.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_NCPR_KGS = data_NCPR_KGS.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_OBV_RSI_Buy = GetDataFromChartink(Condition_OBV_RSI_Buy)\n",
        "    if not data_OBV_RSI_Buy.empty:\n",
        "        data_OBV_RSI_Buy.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_OBV_RSI_Buy = data_OBV_RSI_Buy.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_Strong_Stocks = GetDataFromChartink(Condition_Strong_Stocks)\n",
        "    if not data_Strong_Stocks.empty:\n",
        "        data_Strong_Stocks.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Strong_Stocks = data_Strong_Stocks.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_Bullish_Harami_N100 = GetDataFromChartink(Condition_Bullish_Harami_N100)\n",
        "    if not data_Bullish_Harami_N100.empty:\n",
        "        data_Bullish_Harami_N100.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Bullish_Harami_N100 = data_Bullish_Harami_N100.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    #FS_File1:\n",
        "    data_FII_SH_increase = GetDataFromChartink(Condition_FII_SH_increase)\n",
        "    if not data_FII_SH_increase.empty:\n",
        "        data_FII_SH_increase.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_FII_SH_increase = data_FII_SH_increase.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_Fundamental_Tenchnical_Swing = GetDataFromChartink(Condition_Fundamental_Tenchnical_Swing)\n",
        "    if not data_Fundamental_Tenchnical_Swing.empty:\n",
        "        data_Fundamental_Tenchnical_Swing.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Fundamental_Tenchnical_Swing = data_Fundamental_Tenchnical_Swing.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_Zero_Debt_Momentum = GetDataFromChartink(Condition_Zero_Debt_Momentum)\n",
        "    if not data_Zero_Debt_Momentum.empty:\n",
        "        data_Zero_Debt_Momentum.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Zero_Debt_Momentum = data_Zero_Debt_Momentum.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_FIPA_above_all_SMAs = GetDataFromChartink(Condition_FIPA_above_all_SMAs)\n",
        "    if not data_FIPA_above_all_SMAs.empty:\n",
        "        data_FIPA_above_all_SMAs.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_FIPA_above_all_SMAs = data_FIPA_above_all_SMAs.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "    data_Outperforming_BM_1W_3M = GetDataFromChartink(Condition_Outperforming_BM_1W_3M)\n",
        "    if not data_Outperforming_BM_1W_3M.empty:\n",
        "        data_Outperforming_BM_1W_3M.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Outperforming_BM_1W_3M = data_Outperforming_BM_1W_3M.sort_values(by='per_chg', ascending=False)\n",
        "    \n",
        "# CS_EOD_file1:        \n",
        "    data_Hanging_Man_N100 = GetDataFromChartink(Condition_Hanging_Man_N100)\n",
        "    if not data_Hanging_Man_N100.empty:\n",
        "        data_Hanging_Man_N100.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Hanging_Man_N100 = data_Hanging_Man_N100.sort_values(by='volume', ascending=False)\n",
        "    \n",
        "    data_Bullish_Hammer_Daily_N50 = GetDataFromChartink(Condition_Bullish_Hammer_Daily_N50)\n",
        "    if not data_Bullish_Hammer_Daily_N50.empty:\n",
        "        data_Bullish_Hammer_Daily_N50.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Bullish_Hammer_Daily_N50 = data_Bullish_Hammer_Daily_N50.sort_values(by='volume', ascending=False)\n",
        "    \n",
        "    data_Bullish_Hammer_weekly_N500_near_BB = GetDataFromChartink(Condition_Bullish_Hammer_weekly_N500_near_BB)\n",
        "    if not data_Bullish_Hammer_weekly_N500_near_BB.empty:\n",
        "        data_Bullish_Hammer_weekly_N500_near_BB.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Bullish_Hammer_weekly_N500_near_BB = data_Bullish_Hammer_weekly_N500_near_BB.sort_values(by='volume', ascending=False)\n",
        "\n",
        "    data_Weekly_NCPR_KGS = GetDataFromChartink(Condition_Weekly_NCPR_KGS)\n",
        "    if not data_Weekly_NCPR_KGS.empty:\n",
        "        data_Weekly_NCPR_KGS.drop(['name', 'bsecode','sr'], axis=1, inplace=True)\n",
        "        data_Weekly_NCPR_KGS = data_Weekly_NCPR_KGS.sort_values(by='volume', ascending=False)\n",
        "        \n",
        "# data  = data_BN_NR7 + data_BN_NCPR\n",
        "# print(data_BN_NR7)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt.datetime.now().time().strftime(\"%H:%M:%S\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z-Y89jVGU68g",
        "outputId": "22a46720-7581-4227-b9e5-fb58258b1b95"
      },
      "id": "Z-Y89jVGU68g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'16:29:19'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e59648",
      "metadata": {
        "id": "94e59648"
      },
      "outputs": [],
      "source": [
        "# ID_File1:\n",
        "with open('Sector_Performance.csv', 'w+') as f:\n",
        "    f.write('\\nSector_Performance,,,, \\n')    \n",
        "    f.write('------------------ \\n')    \n",
        "data_Sector_performance.to_csv('Sector_Performance.csv', index = False, mode='a')   #, sep='\\t'\n",
        "\n",
        "# ID_File2:\n",
        "# first file should be in writer mode (overwrite)\n",
        "with open('Chartink_result.csv', 'w+') as f:\n",
        "    f.write('\\nNifty_1Hr_OBV_DIV,,,, \\n')    \n",
        "    f.write('----------------- \\n')    \n",
        "data_1hr_OBV_DI.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "with open('Chartink_result.csv', 'a') as f:\n",
        "    f.write('\\nBN_1Hr_OBV_DIV,,,, \\n')    \n",
        "    f.write('-------------- \\n')    \n",
        "data_1hr_OBV_DI_BN.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "with open('Chartink_result.csv', 'a') as f:\n",
        "    f.write('\\nIntraday_Buy_PSAR,,,, \\n')    \n",
        "    f.write('----------------- \\n')    \n",
        "data_ID_Buy_PSAR.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "with open('Chartink_result.csv', 'a') as f:\n",
        "    f.write('\\nIntraday_Volume_Shocker,,,, \\n')    \n",
        "    f.write('----------------------- \\n')    \n",
        "data_ID_Volume_Shocker.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "with open('Chartink_result.csv', 'a') as f:\n",
        "    f.write('\\nHigh_Relative_Volume_Spurt_5m,,,, \\n')    \n",
        "    f.write('----------------------------- \\n')    \n",
        "data_High_relative_volume_spurt.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "with open('Chartink_result.csv', 'a') as f:\n",
        "    f.write('\\nOpen_High,,,, \\n')    \n",
        "    f.write('--------- \\n')    \n",
        "data_OH.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "with open('Chartink_result.csv', 'a') as f:\n",
        "    f.write('\\nOpen_Low,,,, \\n')    \n",
        "    f.write('-------- \\n')    \n",
        "data_OL.to_csv('Chartink_result.csv', index = False, mode='a')\n",
        "\n",
        "# first file should be in writer mode (overwrite)\n",
        "with open('Candlesticks_Scans_ID.csv', 'w+') as f:\n",
        "    f.write('\\nTweezer_top_15m_Nifty,,,, \\n')    \n",
        "    f.write('--------------------- \\n')    \n",
        "data_Tweezer_top_15m_N50.to_csv('Candlesticks_Scans_ID.csv', index = False, mode='a')\n",
        "\n",
        "with open('Candlesticks_Scans_ID.csv', 'a') as f:\n",
        "    f.write('\\nBullish_Hammer_15m_N500,,,, \\n')    \n",
        "    f.write('----------------------- \\n')    \n",
        "data_Bullish_Hammer_15m_N500.to_csv('Candlesticks_Scans_ID.csv', index = False, mode='a')\n",
        "\n",
        "\n",
        "if dt.datetime.now().time().strftime(\"%H:%M:%S\") >= '15:25:00':\n",
        "# EOD_File1:\n",
        "    with open('EOD_Checks.csv', 'w+') as f:\n",
        "        f.write('\\nVolume_Shocker_Daily,,,, \\n')    \n",
        "        f.write('-------------------- \\n')    \n",
        "    data_Volume_Shocker.to_csv('EOD_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('EOD_Checks.csv', 'a') as f:\n",
        "        f.write('\\nBN_NR7,,,, \\n')    \n",
        "        f.write('------ \\n')    \n",
        "    data_BN_NR7.to_csv(\"EOD_Checks.csv\", index=False, mode='a')\n",
        "\n",
        "    with open('EOD_Checks.csv', 'a') as f:\n",
        "        f.write('\\nBN_NCPR,,,, \\n')    \n",
        "        f.write('------- \\n')    \n",
        "    data_BN_NCPR.to_csv('EOD_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('EOD_Checks.csv', 'a') as f:\n",
        "        f.write('\\nNCPR_KGS,,,, \\n')    \n",
        "        f.write('-------- \\n')    \n",
        "    data_NCPR_KGS.to_csv('EOD_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('EOD_Checks.csv', 'a') as f:\n",
        "        f.write('\\nOBV_RSI_Buy_Daily,,,, \\n')    \n",
        "        f.write('----------------- \\n')    \n",
        "    data_OBV_RSI_Buy.to_csv('EOD_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('EOD_Checks.csv', 'a') as f:\n",
        "        f.write('\\nStrong_Stocks_Daily,,,, \\n')    \n",
        "        f.write('------------------- \\n')    \n",
        "    data_Strong_Stocks.to_csv('EOD_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('EOD_Checks.csv', 'a') as f:\n",
        "        f.write('\\nBullish_Harami_N100,,,, \\n')    \n",
        "        f.write('------------------- \\n')    \n",
        "    data_Bullish_Harami_N100.to_csv('EOD_Checks.csv', index = False, mode='a')\n",
        "\n",
        "# FS_File1:\n",
        "    with open('Fundamental_Checks.csv', 'w+') as f:\n",
        "        f.write('\\nFII_Shareholding_Increased,,,, \\n')    \n",
        "        f.write('-------------------------- \\n')    \n",
        "    data_FII_SH_increase.to_csv('Fundamental_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('Fundamental_Checks.csv', 'a') as f:\n",
        "        f.write('\\nFundamental_Tenchnical_Swing,,,, \\n')    \n",
        "        f.write('---------------------------- \\n')    \n",
        "    data_Fundamental_Tenchnical_Swing.to_csv('Fundamental_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('Fundamental_Checks.csv', 'a') as f:\n",
        "        f.write('\\nZero_Debt_Momentum,,,, \\n')    \n",
        "        f.write('------------------ \\n')    \n",
        "    data_Zero_Debt_Momentum.to_csv('Fundamental_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('Fundamental_Checks.csv', 'a') as f:\n",
        "        f.write('\\nFIPA_above_all_SMAs,,,, \\n')    \n",
        "        f.write('------------------- \\n')    \n",
        "    data_FIPA_above_all_SMAs.to_csv('Fundamental_Checks.csv', index = False, mode='a')\n",
        "\n",
        "    with open('Fundamental_Checks.csv', 'a') as f:\n",
        "        f.write('\\nOutperforming_Nifty_1W_3M,,,, \\n')    \n",
        "        f.write('------------------------- \\n')    \n",
        "    data_Outperforming_BM_1W_3M.to_csv('Fundamental_Checks.csv', index = False, mode='a')\n",
        "\n",
        "# CS_EOD_File1:\n",
        "    with open('Candlestick_EOD_Scans.csv', 'w+') as f:\n",
        "        f.write('\\nHanging_Man_N100,,,, \\n')    \n",
        "        f.write('---------------- \\n')    \n",
        "    data_Hanging_Man_N100.to_csv('Candlestick_EOD_Scans.csv', index = False, mode='a')\n",
        "\n",
        "    with open('Candlestick_EOD_Scans.csv', 'a') as f:\n",
        "        f.write('\\nBullish_Hammer_Daily_N50,,,, \\n')    \n",
        "        f.write('------------------------ \\n')    \n",
        "    data_Bullish_Hammer_Daily_N50.to_csv('Candlestick_EOD_Scans.csv', index = False, mode='a')\n",
        "\n",
        "    with open('Candlestick_EOD_Scans.csv', 'a') as f:\n",
        "        f.write('\\nBullish_Hammer_weekly_near_BB_N500,,,, \\n')    \n",
        "        f.write('---------------------------------- \\n')    \n",
        "    data_Bullish_Hammer_weekly_N500_near_BB.to_csv('Candlestick_EOD_Scans.csv', index = False, mode='a')\n",
        "\n",
        "# adding weekly NCPR here to check with the weekly candlestick scans\n",
        "\n",
        "    with open('Candlestick_EOD_Scans.csv', 'a') as f:\n",
        "        f.write('\\nWekly_NCPR_KGS,,,, \\n')    \n",
        "        f.write('-------------- \\n')    \n",
        "    data_Weekly_NCPR_KGS.to_csv('Candlestick_EOD_Scans.csv', index = False, mode='a')\n",
        "\n",
        "\n",
        "# Convert comma-delimited CSV files to pipe-delimited files\n",
        "# Usage: Drag-and-drop CSV file over script to convert it.\n",
        "\n",
        "# inputPath = sys.argv[1]\n",
        "# outputPath = os.path.dirname(inputPath) + \"/output.csv\"\n",
        "\n",
        "# https://stackoverflow.com/a/52410395/3357935\n",
        "# print(\"Converting CSV to tab-delimited file...\")\n",
        "# with open('Chartink_result.csv') as inputFile:\n",
        "    # newline='' prevents extra newlines when using Python 3 on Windows\n",
        "    # https://stackoverflow.com/a/3348664/3357935\n",
        "#     with open('Chartink_result_final.csv', 'w', newline='\\r\\n') as outputFile:\n",
        "#         reader = csv.DictReader(inputFile, delimiter=',')\n",
        "#         writer = csv.DictWriter(outputFile, reader.fieldnames, delimiter='\\t')\n",
        "#         writer.writeheader()\n",
        "#         writer.writerows(reader)\n",
        "# print(\"Conversion complete.\")\n",
        "# data_BN_NCPR.to_csv(\"Chartink_result.csv\", mode='a', index=False, header=False, lineterminator='\\r\\n')\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fcc1b50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fcc1b50",
        "outputId": "5a99e0b0-8ad4-4c32-8f74-633fbcd80741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n"
          ]
        }
      ],
      "source": [
        "# reader = csv.reader(open(\"Chartink_result.csv\", \"r\"), delimiter=',')\n",
        "# writer = csv.writer(open(\"Chartink_result_final.csv\", 'w', newline=''), delimiter='\\t')\n",
        "# writer.writerows(reader)\n",
        "import os.path\n",
        "if os.path.exists('Chartink_result.csv'):\n",
        "  print ('yes')\n",
        "else:\n",
        "  print ('no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a69ae3f4",
      "metadata": {
        "id": "a69ae3f4"
      },
      "outputs": [],
      "source": [
        "if os.path.exists('/content/mkt_updates/Chartink_result.csv'):\n",
        "  with open('/content/mkt_updates/Chartink_result.csv', mode='r') as fin, open('/content/mkt_updates/Chartink_result_Final.txt', 'w') as fout:\n",
        "      for line in fin:\n",
        "          fout.write(line.replace(',', '\\t\\t'))\n",
        "  fin.close()\n",
        "  fout.close()\n",
        "\n",
        "if os.path.exists('/content/mkt_updates/Sector_Performance.csv'):\n",
        "  with open('/content/mkt_updates/Sector_Performance.csv', mode='r') as fin, open('/content/mkt_updates/Sector_Performance_Final.txt', 'w') as fout:\n",
        "      for line in fin:\n",
        "          fout.write(line.replace(',', '\\t\\t'))\n",
        "  fin.close()\n",
        "  fout.close()\n",
        "\n",
        "if os.path.exists('/content/mkt_updates/Candlesticks_Scans_ID.csv'):\n",
        "  with open('/content/mkt_updates/Candlesticks_Scans_ID.csv', mode='r') as fin, open('/content/mkt_updates/Candlesticks_Scans_ID_Final.txt', 'w') as fout:\n",
        "      for line in fin:\n",
        "          fout.write(line.replace(',', '\\t\\t'))\n",
        "  fin.close()\n",
        "  fout.close()\n",
        "\n",
        "if os.path.exists('/content/mkt_updates/EOD_Checks.csv'):\n",
        "  with open('/content/mkt_updates/EOD_Checks.csv', mode='r') as fin, open('/content/mkt_updates/EOD_Checks_Final.txt', 'w') as fout:\n",
        "      for line in fin:\n",
        "          fout.write(line.replace(',', '\\t\\t'))\n",
        "  fin.close()\n",
        "  fout.close()\n",
        "\n",
        "if os.path.exists('/content/mkt_updates/Fundamental_Checks.csv'):\n",
        "  with open('/content/mkt_updates/Fundamental_Checks.csv', mode='r') as fin, open('/content/mkt_updates/Fundamental_Checks_Final.txt', 'w') as fout:\n",
        "      for line in fin:\n",
        "          fout.write(line.replace(',', '\\t\\t'))\n",
        "  fin.close()\n",
        "  fout.close()\n",
        "\n",
        "if os.path.exists('/content/mkt_updates/Candlestick_EOD_Scans.csv'):\n",
        "  with open('/content/mkt_updates/Candlestick_EOD_Scans.csv', mode='r') as fin, open('/content/mkt_updates/Candlestick_EOD_Scans_Final.txt', 'w') as fout:\n",
        "      for line in fin:\n",
        "          fout.write(line.replace(',', '\\t\\t'))\n",
        "  fin.close()\n",
        "  fout.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e525eaa",
      "metadata": {
        "id": "7e525eaa"
      },
      "outputs": [],
      "source": [
        "# f = open('Chartink_result_final.csv','r')\n",
        "fin.close()\n",
        "fout.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git config --global user.email 'satishcse2004@gmail.com'"
      ],
      "metadata": {
        "id": "S9YzoXSshbL2"
      },
      "id": "S9YzoXSshbL2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add /content/mkt_updates/*.csv\n",
        "!git add /content/mkt_updates/*.txt\n",
        "!git commit -m \"updating files from Colab\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLeXWnlSiAH_",
        "outputId": "76966f77-cd89-4bd3-a66b-f72bdc50fe4d"
      },
      "id": "zLeXWnlSiAH_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/bitnom/colabctl\n",
        "!pip install jedi==0.10\n",
        "!pip uninstall pytest\n",
        "!pip install pluggy==1.0\n",
        "!pip uninsytall notebook\n",
        "!pip install jinja2==3.0.0\n",
        "!pip install apache-airflow"
      ],
      "metadata": {
        "id": "dlTiWrisKRjw"
      },
      "id": "dlTiWrisKRjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/bitnom/colabctl /content/colabctl"
      ],
      "metadata": {
        "id": "FP7C3PtM4jIK"
      },
      "id": "FP7C3PtM4jIK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv\n",
        "# with open('/content/colabctl/notebooks.csv', 'r') as f:\n",
        "#   reader = csv.reader(f)\n",
        "#   for row in reader:\n",
        "#     print (row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eArJBiLn5qMV",
        "outputId": "1d4113ab-8ebb-45b1-ac36-5210146532df"
      },
      "id": "eArJBiLn5qMV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://colab.research.google.com/drive/1OhRD482XDuBACNStNXZ6JWjkBjPpK6yp#scrollTo=1fd8c302']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/colabctl/notebooks.csv', 'w') as f:\n",
        "#   # content = f.read()\n",
        "#   # content = content.replace('old', 'new') # to change specific text\n",
        "#   f.write('https://colab.research.google.com/drive/1OhRD482XDuBACNStNXZ6JWjkBjPpK6yp#scrollTo=1fd8c302')\n",
        "\n",
        "# f.close()"
      ],
      "metadata": {
        "id": "HdCY--lO7nNd"
      },
      "id": "HdCY--lO7nNd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"forkin\"+\"me\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESzy3kje86bM",
        "outputId": "9bd63e56-b0d7-4047-f1f1-ccfc9271c302"
      },
      "id": "ESzy3kje86bM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forkinme\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating function to run the notebook**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0ZFyV_HL26D5"
      },
      "id": "0ZFyV_HL26D5"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gxutw4hDJ52f"
      },
      "id": "Gxutw4hDJ52f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to mount the drive inside google colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D5itJgcuKaRB"
      },
      "id": "D5itJgcuKaRB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etpfjGVrti19"
      },
      "id": "etpfjGVrti19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOwVS4TGvZ5T"
      },
      "id": "FOwVS4TGvZ5T",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "262.969px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}